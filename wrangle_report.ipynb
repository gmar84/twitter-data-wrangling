{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice - Twitter API\n",
    "**Twitter no longer allows API calls, so that step will be skipped and the data set will be downloaded manually**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step - Importing and Assessing the data\n",
    "\n",
    "I imported image-predictions.tsv and tweet-json.txt. After loading that into a dataframe, and running some analysis on it using describe(), info() and data.dtypes, it was clear there were a lot of missing data and incorrect data types.\n",
    "\n",
    "I also ran some counts on columns **id** and **external_entities** to then took a difference which showed 281 total missing entities.\n",
    "\n",
    "Then, to make sure that the tweets were original tweets (and not retweets), I ran **df[df['retweeted'] == True].count()** which returned 0 results. This is good, because that means they are all original tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, I noticed a lot of truncated data in the user column, but I wanted to expand that and see what was in there. To do that, I had to expand the max column width, using **pd.set_option('display.max_colwidth', 0)**, which showed me an object containing everything about the user account.\n",
    "\n",
    "I then noticed another column **display_text_range** which seemed to show the length, or character count, of the **full_text** column. I wanted to make sure it was accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "In order to make sure I was keeping the original data in-tact, I copied the data set to a new one, called df_copy. Then I ran some code to only display the **full_text** and **display_text_range** column, along with a new column I had created - **len_full_text**. The new column takes the length of full_text, so that I could compare it with **display_text_range** to see if the counts were accurate. As I suspected, they were not all accurate, so using the new column I created would give an accurate count.\n",
    "\n",
    "I also noticed in my assessment that **id** and **id_str** were showing as numbers, but displaying a decimal in the data set. Checking the dtypes, they were shown as integers, which caused them to display funny. So changing these to strings would fix that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, I removed all the columns which contained null or NaN data, since keeping these in the data set would cause any analysis we do to seem messy and cluttered. I used **df_copy.drop(columns** to drop all the affected columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the data\n",
    "\n",
    "I used **df_copy.to_csv('twitter_archive_master.csv', sep='\\t', encoding='utf-8')** to export the data to a csv file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "\n",
    "I used matplotlib and numpy to create a scatter graph of the **len_full_text** and **favorite_count** columns, hoping to see a correlation between tweets that were lengthier in description and number of favorites. I found that this was not generally the case, so no significant correlation between these two columns were noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
